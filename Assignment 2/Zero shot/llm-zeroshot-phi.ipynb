{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-21T19:30:29.509940Z","iopub.execute_input":"2024-09-21T19:30:29.510827Z","iopub.status.idle":"2024-09-21T19:30:29.901380Z","shell.execute_reply.started":"2024-09-21T19:30:29.510770Z","shell.execute_reply":"2024-09-21T19:30:29.900623Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport re\nimport pickle\nimport time \nimport os","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:32.943964Z","iopub.execute_input":"2024-09-21T19:30:32.944699Z","iopub.status.idle":"2024-09-21T19:30:37.185942Z","shell.execute_reply.started":"2024-09-21T19:30:32.944656Z","shell.execute_reply":"2024-09-21T19:30:37.185137Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"splits = {'test': 'college_mathematics/test-00000-of-00001.parquet', 'validation': 'college_mathematics/validation-00000-of-00001.parquet', 'dev': 'college_mathematics/dev-00000-of-00001.parquet'}\ndf = pd.read_parquet(\"hf://datasets/cais/mmlu/\" + splits[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:37.187767Z","iopub.execute_input":"2024-09-21T19:30:37.188639Z","iopub.status.idle":"2024-09-21T19:30:39.114889Z","shell.execute_reply.started":"2024-09-21T19:30:37.188568Z","shell.execute_reply":"2024-09-21T19:30:39.113973Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_prompts_zs(df):\n    prompts = []\n    answers = []\n    for index, row in df.iterrows():\n        #\n        prompt = \"Choose the answer of the given question from the below options.\\n\"+row['question']+ \"\\n\"+\"{1:\"+row['choices'][0]+\"}\" + \"\\n\"+\"{2:\"+row['choices'][1]+\"}\" + \"\\n\"+\"{3:\"+row['choices'][2]+\"}\"+ \"\\n\"+\"{4:\"+row['choices'][3]+\"}\"+\"\\n\" + \"answer: {\"\n        prompts.append(prompt)\n        answers.append(str(row['answer']))\n    return prompts, answers","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:39.116297Z","iopub.execute_input":"2024-09-21T19:30:39.116711Z","iopub.status.idle":"2024-09-21T19:30:39.123684Z","shell.execute_reply.started":"2024-09-21T19:30:39.116666Z","shell.execute_reply":"2024-09-21T19:30:39.122808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"prompts_zs, answers = create_prompts_zs(df)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:39.125881Z","iopub.execute_input":"2024-09-21T19:30:39.126477Z","iopub.status.idle":"2024-09-21T19:30:39.147811Z","shell.execute_reply.started":"2024-09-21T19:30:39.126434Z","shell.execute_reply":"2024-09-21T19:30:39.146883Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for i in range(len(answers)):\n    answers[i] = int(answers[i])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:40.860343Z","iopub.execute_input":"2024-09-21T19:30:40.861306Z","iopub.status.idle":"2024-09-21T19:30:40.866611Z","shell.execute_reply.started":"2024-09-21T19:30:40.861252Z","shell.execute_reply":"2024-09-21T19:30:40.865635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/Phi-3.5-mini-instruct\", \n    device_map=\"cuda\", \n    torch_dtype=\"auto\", \n    trust_remote_code=True, \n)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:30:44.544548Z","iopub.execute_input":"2024-09-21T19:30:44.545236Z","iopub.status.idle":"2024-09-21T19:32:25.356865Z","shell.execute_reply.started":"2024-09-21T19:30:44.545196Z","shell.execute_reply":"2024-09-21T19:32:25.355815Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4a60eb775d4d368dfe8b074fa1fb9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84fbd7124ba04d31a801e8819cc53333"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a0eb885ced94685a9e731531e5608fc"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2c4dc4d712648e0bdc2772c198f234b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f83c7281d0264d18ab34e12ad9df53ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f33a8e2ab574ee3b7ecf374c9711a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abbcf97aa6434fdfb169fcb5eb098925"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb50709bfe104887bbf20effe75f35ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f35d499f474d668dd417ae39963c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48f050ab6e240769d7d687a4b186ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbe813acf684f0a8850d730d07a9d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c5481859c9459686d626fa51bb9916"}},"metadata":{}}]},{"cell_type":"code","source":"predictions_zeroshot_phi = []\nbegin = time.time()\nfor i in range(len(prompts_zs)):\n    print(i)\n    input_text = prompts_zs[i]\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(**input_ids,max_length = 200)\n    response = tokenizer.decode(outputs[0])\n    #print(response)\n    match = re.search(r\"answer: \\{(\\d+)\", response)\n    extracted_character = match.group(1) if match else '1'\n    if(extracted_character in ['1','2','3','4']):\n        extracted_number = int(extracted_character)-1\n    else:\n        extracted_number = 0\n    predictions_zeroshot_phi.append(extracted_number)\nend = time.time()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:35:14.312218Z","iopub.execute_input":"2024-09-21T19:35:14.312626Z","iopub.status.idle":"2024-09-21T19:44:43.760956Z","shell.execute_reply.started":"2024-09-21T19:35:14.312564Z","shell.execute_reply":"2024-09-21T19:44:43.760175Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_accuracy(predictions, answers):\n    valid_pairs = [(pred, ans) for pred, ans in zip(predictions, answers) if pred is not None]\n    correct_predictions = sum(1 for pred, ans in valid_pairs if pred == ans)\n    accuracy = correct_predictions / len(valid_pairs) if valid_pairs else 0\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:44:47.473954Z","iopub.execute_input":"2024-09-21T19:44:47.474319Z","iopub.status.idle":"2024-09-21T19:44:47.480009Z","shell.execute_reply.started":"2024-09-21T19:44:47.474284Z","shell.execute_reply":"2024-09-21T19:44:47.478955Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"filename = 'predictions_zeroshot_phi.pkl'\nwith open(filename, 'wb') as file:\n    pickle.dump(predictions_zeroshot_phi, file)\nwith open(filename, 'rb') as file:\n    predictions_zeroshot_phi = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:44:50.208587Z","iopub.execute_input":"2024-09-21T19:44:50.208981Z","iopub.status.idle":"2024-09-21T19:44:50.214305Z","shell.execute_reply.started":"2024-09-21T19:44:50.208944Z","shell.execute_reply":"2024-09-21T19:44:50.213401Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Zero shot prompting on Phi\")\nprint(\"Total inference time:\",end-begin,\"seconds\")\nprint(\"Accuracy score:\",100*calculate_accuracy(predictions_zeroshot_phi,answers),\"%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T19:45:11.961130Z","iopub.execute_input":"2024-09-21T19:45:11.961515Z","iopub.status.idle":"2024-09-21T19:45:11.966931Z","shell.execute_reply.started":"2024-09-21T19:45:11.961476Z","shell.execute_reply":"2024-09-21T19:45:11.966040Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Zero shot prompting on Phi\nTotal inference time: 569.4420506954193 seconds\nAccuracy score: 34.0 %\n","output_type":"stream"}]}]}